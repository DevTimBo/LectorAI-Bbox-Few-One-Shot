{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f979c8-0b88-4fe3-916b-862f64597d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python Standard Library dependencies\n",
    "import datetime\n",
    "from functools import partial\n",
    "from glob import glob\n",
    "import json\n",
    "import math\n",
    "import multiprocessing\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "from typing import Any, Dict, Optional\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Import utility functions\n",
    "from cjm_psl_utils.core import download_file, file_extract, get_source_code\n",
    "from cjm_pil_utils.core import resize_img, get_img_files, stack_imgs\n",
    "from cjm_pytorch_utils.core import pil_to_tensor, tensor_to_pil, get_torch_device, set_seed, denorm_img_tensor, move_data_to_device\n",
    "from cjm_pandas_utils.core import markdown_to_pandas, convert_to_numeric, convert_to_string\n",
    "from cjm_torchvision_tfms.core import ResizeMax, PadSquare, CustomRandomIoUCrop\n",
    "\n",
    "# Import the distinctipy module\n",
    "from distinctipy import distinctipy\n",
    "\n",
    "# Import matplotlib for creating plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Import the pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# Set options for Pandas DataFrame display\n",
    "pd.set_option('max_colwidth', None)  # Do not truncate the contents of cells in the DataFrame\n",
    "pd.set_option('display.max_rows', None)  # Display all rows in the DataFrame\n",
    "pd.set_option('display.max_columns', None)  # Display all columns in the DataFrame\n",
    "\n",
    "# Import PIL for image manipulation\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Import PyTorch dependencies\n",
    "import torch\n",
    "from torch.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from torchtnt.utils import get_module_summary\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "from torchvision.tv_tensors import BoundingBoxes, Mask\n",
    "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
    "import torchvision.transforms.v2  as transforms\n",
    "from torchvision.transforms.v2 import functional as TF\n",
    "from torchsummary import summary\n",
    "\n",
    "# Import Mask R-CNN\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn_v2, MaskRCNN\n",
    "from torchvision.models.detection import MaskRCNN_ResNet50_FPN_V2_Weights\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "# Import tqdm for progress bar\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfef79d-942d-46a3-88d0-e7d00adb257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file_path = \"C:/Users/Anwender/Downloads/LectorAI_SOSE24/dokumentenklassifikation/workspace/mix_up_data/xml/AG_016.xml\"\n",
    "image_file_path = \"C:/Users/Anwender/Downloads/LectorAI_SOSE24/dokumentenklassifikation/workspace/mix_up_data/Bilder/AG_016.jpeg\"\n",
    "\n",
    "WORKSPACE_PATH = 'C:/Users/Anwender/Downloads/LectorAI_SOSE24/dokumentenklassifikation/workspace/'\n",
    "IMAGES_ALL = WORKSPACE_PATH + '/mix_up_data/Bilder'\n",
    "ANNOTATION_PATH_ALL =  WORKSPACE_PATH + '/mix_up_data/xml'\n",
    "ANNOTATION_PATH_ALL_JSON =  WORKSPACE_PATH + '/mix_up_data/all_json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662229c5-6925-4197-9cdd-00400b20fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import base64\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def xml_to_json(xml_file_path, image_file_path, target_height=1024, target_width=1024):\n",
    "    # Parse XML data from file\n",
    "    tree = ET.parse(xml_file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Read and encode image data\n",
    "    with open(image_file_path, \"rb\") as image_file:\n",
    "        image_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "    # Get image dimensions from XML\n",
    "    size = root.find('size')\n",
    "    original_width = float(size.find('width').text)\n",
    "    original_height = float(size.find('height').text)\n",
    "    \n",
    "    # Initialize the JSON structure\n",
    "    json_data = {\n",
    "        \"version\": \"5.4.1\",\n",
    "        \"flags\": {},\n",
    "        \"shapes\": [],\n",
    "        \"imagePath\": image_file_path,\n",
    "        \"imageData\": image_data,\n",
    "        \"imageHeight\": target_height,\n",
    "        \"imageWidth\": target_width\n",
    "    }\n",
    "\n",
    "    # Iterate through each object in the XML\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text\n",
    "        bndbox = obj.find('bndbox')\n",
    "        xmin = float(bndbox.find('xmin').text)\n",
    "        ymin = float(bndbox.find('ymin').text)\n",
    "        xmax = float(bndbox.find('xmax').text)\n",
    "        ymax = float(bndbox.find('ymax').text)\n",
    "\n",
    "        # Normalize the bounding box points\n",
    "        normalized_points = [\n",
    "            [xmin * target_width / original_width, ymin * target_height / original_height],\n",
    "            [xmin * target_width / original_width, ymax * target_height / original_height],\n",
    "            [xmax * target_width / original_width, ymax * target_height / original_height],\n",
    "            [xmax * target_width / original_width, ymin * target_height / original_height]\n",
    "        ]\n",
    "\n",
    "        # Create shape entry\n",
    "        shape = {\n",
    "            \"label\": label,\n",
    "            \"points\": normalized_points,\n",
    "            \"group_id\": None,\n",
    "            \"description\": \"\",\n",
    "            \"shape_type\": \"polygon\",\n",
    "            \"flags\": {},\n",
    "            \"mask\": None\n",
    "        }\n",
    "\n",
    "        # Add shape entry to shapes list\n",
    "        json_data[\"shapes\"].append(shape)\n",
    "    \n",
    "    return json_data\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857d938d-752b-49f7-a11e-47e9f0b323e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image_file(image_base_name, images_folder_path):\n",
    "    possible_extensions = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']\n",
    "    for ext in possible_extensions:\n",
    "        image_file_path = os.path.join(images_folder_path, image_base_name + ext)\n",
    "        if os.path.exists(image_file_path):\n",
    "            return image_file_path\n",
    "    return None\n",
    "\n",
    "def process_xml_folder(xml_folder_path, images_folder_path, json_output_folder, target_height=1024, target_width=1024):\n",
    "    os.makedirs(json_output_folder, exist_ok=True)\n",
    "\n",
    "    # Iterate over all XML files in the folder\n",
    "    for xml_file_name in os.listdir(xml_folder_path):\n",
    "        if xml_file_name.endswith('.xml'):\n",
    "            # Construct full XML file path\n",
    "            xml_file_path = os.path.join(xml_folder_path, xml_file_name)\n",
    "            image_base_name = os.path.splitext(xml_file_name)[0] \n",
    "            \n",
    "            image_file_path = find_image_file(image_base_name, images_folder_path)\n",
    "            if image_file_path is None:\n",
    "                print(f\"Error: No image file found for {xml_file_name}\")\n",
    "                continue\n",
    "            \n",
    "            # Convert XML to JSON\n",
    "            json_data = xml_to_json(xml_file_path, image_file_path, target_height, target_width)\n",
    "            \n",
    "            # Determine JSON output path\n",
    "            json_file_name = xml_file_name.replace('.xml', '.json')\n",
    "            json_output_path = os.path.join(json_output_folder, json_file_name)\n",
    "            \n",
    "            # Write JSON data to file\n",
    "            with open(json_output_path, 'w') as json_file:\n",
    "                json.dump(json_data, json_file, indent=4)\n",
    "            \n",
    "            print(f\"Processed {xml_file_name} and saved to {json_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fad666-3f87-4daa-836b-85a619f0a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_folder_path = ANNOTATION_PATH_ALL\n",
    "images_folder_path = IMAGES_ALL\n",
    "json_output_folder = ANNOTATION_PATH_ALL_JSON\n",
    "process_xml_folder(xml_folder_path, images_folder_path, json_output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ec8e97-341d-4d9d-9dca-c254cc07a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert XML to JSON\n",
    "json_output = xml_to_json(xml_file_path, image_file_path)\n",
    "print(json.dumps(json_output, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81875c23-a1f5-4aff-a628-5634c0c9fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output_path = \"C:/Users/Anwender/Downloads/LectorAI_SOSE24/dokumentenklassifikation/MASKRCNN/MASKRCNN/test_folder/images/AG_016.json\"\n",
    "# Write JSON output to a file with pretty formatting\n",
    "with open(json_output_path, 'w') as json_file:\n",
    "    json.dump(json_output, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9517455f-2e1d-491f-bca9-432d483f09ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output_path = \"C:/Users/Anwender/Downloads/LectorAI_SOSE24/dokumentenklassifikation/MASKRCNN/MASKRCNN/test_folder/images\"\n",
    "json_output_path_f = Path(json_output_path)\n",
    "annotation_file_path = list(json_output_path_f.glob('*.json'))\n",
    "# Create a generator that yields Pandas DataFrames containing the data from each JSON file\n",
    "cls_dataframes = (pd.read_json(f, orient='index').transpose() for f in tqdm(annotation_file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed4dc40-f4fc-49bf-bc73-9de236c5f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the DataFrames into a single DataFrame\n",
    "annotation_df = pd.concat(cls_dataframes, ignore_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3404ba6a-0906-4df3-86d1-5d5f54b186e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d3dfeb-ac99-42a2-8254-feffeb77be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the image file name as the index for each row\n",
    "annotation_df['index'] = annotation_df['imagePath'].apply(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
    "\n",
    "# Set the new index\n",
    "annotation_df = annotation_df.set_index('index')\n",
    "\n",
    "# Print the unique values of imagePath to verify\n",
    "print(annotation_df['imagePath'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3da4a8-60ee-4d9c-8d66-da2132055dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output_path_f = get_img_files(json_output_path)\n",
    "\n",
    "img_dict = {file.stem : file for file in json_output_path_f}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990fbf39-368d-4949-b38b-7492d5848ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce2b71-4ccf-4ad1-9cf1-794f275017a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_df['imagePath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a594f88a-cc47-4321-ac42-e7b3185f653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes_df = annotation_df['shapes'].explode().to_frame().shapes.apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5024933-2df7-4a7e-a9d3-12814ab402ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of unique labels in the 'annotation_df' DataFrame\n",
    "class_names = shapes_df['label'].unique().tolist()\n",
    "\n",
    "# Display labels using a Pandas DataFrame\n",
    "pd.DataFrame(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1f3060-4fb0-41c1-9a91-923478d2f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepend a `background` class to the list of class names\n",
    "class_names = ['background']+class_names\n",
    "\n",
    "# Display labels using a Pandas DataFrame\n",
    "pd.DataFrame(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa353d66-f0ae-4405-98a6-2d9d9dfaa38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of colors with a length equal to the number of labels\n",
    "colors = distinctipy.get_colors(len(class_names))\n",
    "\n",
    "# Make a copy of the color map in integer format\n",
    "int_colors = [tuple(int(c*255) for c in color) for color in colors]\n",
    "\n",
    "# Generate a color swatch to visualize the color map\n",
    "distinctipy.color_swatch(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5132aceb-06ca-4c17-914a-bc5d505330d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the font file\n",
    "font_file = 'KFOlCnqEu92Fr1MmEU9vAw.ttf'\n",
    "\n",
    "# Download the font file\n",
    "download_file(f\"https://fonts.gstatic.com/s/roboto/v30/{font_file}\", \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d3952e-206c-4cbe-a7cc-e4f436976e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the file ID of the first image file\n",
    "file_id = list(img_dict.keys())[3]\n",
    "\n",
    "# Open the associated image file as a RGB image\n",
    "sample_img = Image.open(img_dict[file_id]).convert('RGB')\n",
    "\n",
    "# Print the dimensions of the image\n",
    "print(f\"Image Dims: {sample_img.size}\")\n",
    "\n",
    "# Show the image\n",
    "sample_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d23211c-cbd5-4757-96c2-aa3c135014b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the row from the 'annotation_df' DataFrame corresponding to the 'file_id'\n",
    "\n",
    "annotation_df.loc[file_id].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897959ed-6885-45e1-90e1-c49ae47f9a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_polygon_mask(image_size, vertices):\n",
    "    \"\"\"\n",
    "    Create a grayscale image with a white polygonal area on a black background.\n",
    "\n",
    "    Parameters:\n",
    "    - image_size (tuple): A tuple representing the dimensions (width, height) of the image.\n",
    "    - vertices (list): A list of tuples, each containing the x, y coordinates of a vertex\n",
    "                        of the polygon. Vertices should be in clockwise or counter-clockwise order.\n",
    "\n",
    "    Returns:\n",
    "    - PIL.Image.Image: A PIL Image object containing the polygonal mask.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a new black image with the given dimensions\n",
    "    mask_img = Image.new('L', image_size, 0)\n",
    "\n",
    "    # Draw the polygon on the image. The area inside the polygon will be white (255).\n",
    "    ImageDraw.Draw(mask_img, 'L').polygon(vertices, fill=(255))\n",
    "\n",
    "    # Return the image with the drawn polygon\n",
    "    return mask_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76486337-901c-4ba8-aa25-f77637e780ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bboxes = partial(draw_bounding_boxes, fill=False, width=2, font=font_file, font_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7717759-1e97-4016-9cd4-ea083f5604f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the labels for the sample\n",
    "labels = [shape['label'] for shape in annotation_df.loc[file_id]['shapes']]\n",
    "# Extract the polygon points for segmentation mask\n",
    "shape_points = [shape['points'] for shape in annotation_df.loc[file_id]['shapes']]\n",
    "# Format polygon points for PIL\n",
    "xy_coords = [[tuple(p) for p in points] for points in shape_points]\n",
    "# Generate mask images from polygons\n",
    "mask_imgs = [create_polygon_mask(sample_img.size, xy) for xy in xy_coords]\n",
    "# Convert mask images to tensors\n",
    "masks = torch.concat([Mask(transforms.PILToTensor()(mask_img), dtype=torch.bool) for mask_img in mask_imgs])\n",
    "# Generate bounding box annotations from segmentation masks\n",
    "bboxes = torchvision.ops.masks_to_boxes(masks)\n",
    "\n",
    "# Annotate the sample image with segmentation masks\n",
    "annotated_tensor = draw_segmentation_masks(\n",
    "    image=transforms.PILToTensor()(sample_img),\n",
    "    masks=masks,\n",
    "    alpha=0.3,\n",
    "    colors=[int_colors[i] for i in [class_names.index(label) for label in labels]]\n",
    ")\n",
    "\n",
    "# Annotate the sample image with labels and bounding boxes\n",
    "annotated_tensor = draw_bboxes(\n",
    "    image=annotated_tensor,\n",
    "    boxes=bboxes,\n",
    "    labels=labels,\n",
    "    colors=[int_colors[i] for i in [class_names.index(label) for label in labels]]\n",
    ")\n",
    "\n",
    "tensor_to_pil(annotated_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d000b7c9-e96e-422b-87e8-b6d73f078a13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
