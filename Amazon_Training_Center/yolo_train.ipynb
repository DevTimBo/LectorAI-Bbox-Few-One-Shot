{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author: Jason Pranata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = 'train_dataset/Images'\n",
    "val_images_path = 'val_dataset/Images'\n",
    "test_images_path = 'test_dataset/Images'\n",
    "output_train_images_path = 'train_dataset/resized_Images'\n",
    "output_val_images_path = 'val_dataset/resized_Images'\n",
    "output_test_images_path = 'test_dataset/resized_Images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(input_path, output_path, target_size=(1024, 1024)):\n",
    "    for image_file in os.listdir(input_path):\n",
    "        if not image_file.endswith('.jpg') and not image_file.endswith('.jpeg') and not image_file.endswith('.JPG'):\n",
    "            continue\n",
    "        img = cv2.imread(os.path.join(input_path, image_file))\n",
    "        img_resized = cv2.resize(img, target_size)\n",
    "        cv2.imwrite(os.path.join(output_path, image_file), img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize_images(train_images_path, output_train_images_path)\n",
    "#resize_images(val_images_path, output_val_images_path)\n",
    "#resize_images(test_images_path, output_test_images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(image_path, annotation_path, output_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    with open(annotation_path, 'r') as file:\n",
    "        annotations = file.readlines()\n",
    "\n",
    "    for annotation in annotations:\n",
    "        class_id, x_center, y_center, bbox_width, bbox_height = map(float, annotation.strip().split())\n",
    "\n",
    "        x_center *= width\n",
    "        y_center *= height\n",
    "        bbox_width *= width\n",
    "        bbox_height *= height\n",
    "\n",
    "        x1 = int(x_center - bbox_width / 2)\n",
    "        y1 = int(y_center - bbox_height / 2)\n",
    "        x2 = int(x_center + bbox_width / 2)\n",
    "        y2 = int(y_center + bbox_height / 2)\n",
    "\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(image, str(int(class_id)), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "def check_labels():\n",
    "    for i in range(0, 1):\n",
    "        num = i\n",
    "        image_path = f'val_dataset/resized_Images/AG_0{num}.jpg'\n",
    "        annotation_path = f'val_dataset/labels/AG_0{num}.txt'\n",
    "        output_path = f'valD_image{num}.jpg'\n",
    "        draw_bounding_boxes(image_path, annotation_path, output_path)\n",
    "\n",
    "#check_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training (manually adjust weights, configs, etc. accordingly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('runs/detect/train8/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict('test_dataset/resized_Images/AG_043.jpg', save = True)\n",
    "model.predict('test_dataset/resized_Images/AD_043.jpg', save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_path = os.path.abspath('yolov8_transferlearn_config.yaml')\n",
    "train_results = model.train(data=yaml_path, epochs=300, batch=2, imgsz=1024, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results = model.val(data=yaml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ad = 'test_dataset/resized_Images/AD_043.jpg'\n",
    "test_ag = 'test_dataset/resized_Images/AG_043.jpg'\n",
    "model.predict(test_ag, save = True)\n",
    "model.predict(test_ad, save = True)\n",
    "model.predict(\"/mnt/c/Users/jason/GitHubRepos/LectorAI-TextExtraction/tempimages_api/beispiel_form_covered.jpg\", save = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "everything",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
